# 6. データベースとデータモデル

このデモでは **`sensors`** という Cosmos DB データベースを使い、3 つの
コンテナを使用します。それぞれの役割とパーティション戦略を理解する
ことが、スケーラブルな Change Feed ソリューションを設計するために
重要です。

## `readings` コンテナ

`readings` はジェネレーターが生成する生の温度計測値を保存します。
ドキュメント構造の例を以下に示します。

```json
{
  "id": "<uuid>",
  "sensor_id": "sensor-1",
  "temperature": 27.5,
  "timestamp": "2025-10-29T01:05:58Z"
}
```

* **パーティションキー** – `/sensor_id`。同じセンサーのデータが同じ
  パーティションに保存されるため、Change Feed の処理や最近の
  データ取得が効率化されます。
* **TTL (Time To Live)** – このデモでは設定していません。実運用では
  `readings` コンテナに TTL を設定し、古いデータを自動的に削除する
  ことでストレージコストを制御できます。

センサーがデータを送信する頻度に応じて、`readings` コンテナに割り当てる
スループット（RU/s）を検討します。数台のセンサーが数秒おきにデータを
送るだけなら 400 RU/s のオートスケールで十分ですが、センサーが数万台
規模になる場合は大きくスケールアップする必要があります。Azure Monitor
の RU 使用量メトリックを監視し、`main.bicep` のオートスケール上限を
調整することをお勧めします。

また、Change Feed はパーティション境界に従うため、`/sensor_id` を
パーティションキーにすることで特定センサーの最新 10 件を単一
パーティションから取得できます。日付や地域など別のキーを使うと
1 センサーのデータが複数パーティションに分散し、クエリや集計が
複雑になる場合があります【437749716107481†L47-L66】。アクセスパターンに
基づいて設計してください。

## `summaries` コンテナ

`summaries` には、サマライザーが計算したセンサーごとの統計値が保存
されます。各ドキュメントは、過去 10 回の読み取りに基づく
最大値・最小値・平均値を表します。

```json
{
  "id": "<uuid>",
  "timestamp": "2025-10-29T01:06:10Z",
  "sensor_id": "sensor-1",
  "max_temp": 33.7,
  "min_temp": 21.4,
  "avg_temp": 28.5
}
```

* **パーティションキー** – `/sensor_id`。`readings` と同じキーを使用
  することで、関連データが同じパーティションに格納されます。
* **保持期間** – 各サマリはある時点のスナップショットを示します。
  可視化だけに使用する場合は、TTL を設定して最新のサマリのみを
  保存することもできます。

サマリは 1 件あたりのサイズが小さいため、`readings` より多くの履歴を
保持できます。それでもサマライザーがデータ到着のたびにサマリを出力
する場合、ドキュメント数は急速に増加します。可視化に一定期間の履歴
のみが必要な場合は、TTL を数時間または数日程度に設定しコンテナサイズ
を抑えます。TTL による削除でも Change Feed イベントが生成される
ため、`summaries` コンテナの Change Feed を利用する際にはロジックを
工夫してください。

## `leases` コンテナ

Change Feed プロセッサは、どこまで読み取ったかを記録するために
リー スコンテナを使用します。リー スドキュメントには継続トークン
やその他のメタデータが含まれ、再起動後も前回の位置から処理を
再開できます。このデモでは、`summariser` のリー ス ID は
`readings_changefeed_lease` に固定されています。

## パーティションキーの重要性

Change Feed はソースコンテナと同じパーティション境界に従います。
適切なパーティションキーを選ぶことでスケーラビリティや処理効率が
大きく向上します。このデモでは `/sensor_id` を使用し、センサー
単位で順序通りにデータを処理できるようにしています。

マルチテナント環境では、テナント ID とセンサー ID を組み合わせた
複合キー（例: `/tenant_id/sensor_id`）を使用して、異なるテナントの
データを物理的に分離することができます。また、センサー ID が偏った
分布を持つ場合、ハッシュプレフィックスを付与した **合成キー** により
書き込みを均等に分散させることも可能です。

一度コンテナを作成するとパーティションキーを変更することはできません。
アクセスパターンやスループット要件、データ分布特性を十分に検討して
キーを決めることが重要です。

## インデックスと TTL の設定

Cosmos DB はデフォルトですべてのプロパティをインデックスしますが、用途に応じてポリシーを調整することで性能とコストのバランスを取ることができます。

* **不要なパスの除外** – クエリに使用しない大きなプロパティや配列がある場合は、`excludedPaths` に指定してインデックス対象から外します。これによりインデックスサイズと書き込み時の RU 消費を削減できます。
* **複合インデックス** – 複数フィールドでフィルタやソートを行う場合は、`compositeIndexes` を定義してフルスキャンを避けます。例えば `sensor_id` でグループ化し `timestamp` で降順ソートするクエリに合わせた複合インデックスが有効です。
* **TTL とソフト削除** – コンテナに既定の Time To Live を設定すると、一定時間後にアイテムが自動削除されます。`readings` や `summaries` に TTL を設定することで古いデータが残り続けるのを防げます。TTL による削除も Change Feed にイベントが流れるため、ロジック側で `expiry` イベントを処理する必要があります。

## ストレージパターンとホット・コールドデータ

全てのデータを永遠に Cosmos DB に残す必要はありません。ワークロードに応じて階層化ストレージを検討します。

* **ホット層 (Cosmos DB)** – 低レイテンシが求められる最新のセンサーデータやサマリを保持します。TTL を設定して 24 時間など一定期間経過後にデータを削除します。
* **コールド層 (Blob / Data Lake)** – 古い `readings` を定期的に Azure Blob Storage や Data Lake にアーカイブします。これにより Cosmos DB のストレージコストを削減しつつ、バッチ分析に利用できます。
* **集計用層** – 時間単位や日次で事前集計したメトリックを専用コンテナや Synapse Link 等に保存します。ビジュアライザーは長期的な傾向分析にこの層を参照します。

適切なデータ保持・アーカイブポリシーを設計することで、コスト効率を高め Change Feed の処理量も制御できます。

## RU の監視とパフォーマンスチューニング

Cosmos DB の課金はスループットとストレージに基づきます。次の点を意識して RU 消費を最適化します。

* **メトリクスの監視** – Azure Monitor で RU 使用量、レイテンシ、スロットリングされた要求、ストレージ使用量を追跡します。使用量が上限に近づいたらアラートを設定し、スループットを増やすかクエリを最適化します。
* **Autoscale の上限調整** – バースト型の負荷に対応する場合は `maxThroughput` を高めに設定し、安定したワークロードでは手動スループットとスケジュール変更を検討します。CLI から `az cosmosdb sql container throughput update` を利用して cron ベースで設定を変更できます。
* **クエリの最適化** – SQL で必要なフィールドのみを選択し (`SELECT c.sensor_id, c.temperature` など)、`SELECT *` を避けてネットワークと RU の使用を削減します。パラメータ化クエリを使うことでサーバ側キャッシュが効率的に利用されます。
* **バルク操作の利用** – 書き込みをまとめて行うことでネットワーク往復を減らし、スループットを向上させることができます。ストアドプロシージャやバルクエグゼキュータライブラリを活用します。

これらのテクニックを組み合わせ、パーティションキー設計やインデックス最適化と併せて管理することで、アプリケーションの成長に合わせてスケールするデータ層を構築できます。

## 高度なモデリングパターン

センサーテレメトリのスキーマ設計では、以下のような発展的パターンを検討できます。

* **単一コンテナ vs 複数コンテナ** – 本ラボでは全てのセンサーを `sensor_id` でパーティションした単一コンテナに格納していますが、センサー種別や顧客単位でコンテナを分けることでワークロードの分離や SLA の管理が容易になります。データベース単位のスループットを使用すれば、複数コンテナで RU/s を共有できます。
* **スキーマバージョン管理** – デバイスのアップデートに伴いフィールドが増減することがあります。オプションのプロパティや `_schemaVersion` フィールドでバージョンを管理し、大きなバイナリは同じドキュメントに入れず Azure Storage へのポインタで参照します。
* **複合ドキュメント** – 複数のイベントを 1 つのドキュメントにまとめることで RU 消費を抑えるパターンです。例えば 1 日分の読み取りを配列で格納することもできます。ただし単一イベントの更新が難しくなり、ポイント読み取りのコストが増加します。
* **マテリアライズドプロジェクション** – 時間単位の集約や平均値などを別コンテナに保存して、メインコンテナへの負荷を下げる設計です。特定のクエリに最適化されたビューを維持することで、クエリ遅延を大幅に改善できます。
* **階層的パーティションキー** – `tenant_id`、`device_type`、`sensor_id` を連結したキーを採用することで、関連するセンサーを同じパーティションにまとめつつ、`IN` 句による広範囲の問い合わせを可能にします。

## キャパシティ計画と課金

Cosmos DB ではプロビジョンドスループットとストレージの両方で課金されます。効果的に予算を立てるために:

* **RU 消費の見積もり** – 読み取りはドキュメントサイズに概ね比例し、書き込みは 1 KB あたり約 5 RU を消費します。公式の [Request Unit Calculator](https://cosmos.azure.com/capacitycalculator) を使ってスキーマの消費を試算しましょう。サマリードキュメントは小さいため必要な RU は少なくなります。
* **階層 TTL の採用** – コンテナに `defaultTtl` を設定して、生データを一定期間（例えば 30 日）で自動削除します。個別のドキュメントで TTL を上書きして、長期間保存することもできます。サマリーには長めの TTL を設定して分析を可能にします。
* **ストレージ利用の監視** – Azure ポータルで保存容量の増加を監視し、アラートを設定します。サマライザーが古い状態を破棄するようなクリーンアップポリシーで不要なデータを抑制します。
* **コスト分析ツールの活用** – Azure Cost Management や請求エクスポートを使って、RU 使用量をリソースやテナント別に割り当てます。月次でトレンドを確認し、リソースにタグを付けて費用配分を明確にします。

これらの高度なモデリングとキャパシティ計画の技術を取り入れることで、ビジネス要件の変化に対応しながらコストを抑えた堅牢なデータ設計が可能になります。
