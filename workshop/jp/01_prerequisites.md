# 1. 事前準備と対象者

## 対象読者

このハンズオンラボは、**Azure Cosmos DB** を初めて利用する開発者やアーキテクトを対象にしています。
Change Feed を用いたイベント駆動型アプリケーションの構築方法を学びたい方に適しています。
Cosmos DB や Container Apps の経験は不要ですが、Python とコマンドラインの基礎知識があると理解がスムーズです。

## 許可とサブスクリプション

ラボを実施するには次の条件が必要です。

* **Azure サブスクリプション** – リソースグループを作成し、リソースをデプロイできる権限が必要です。
  Pay‑As‑You‑Go や MSDN サブスクリプションで十分です。
  サブスクリプションをお持ちでない場合は [Azure 無料アカウント](https://azure.microsoft.com/free/) からサインアップできます。
* サブスクリプション内で新しい **リソースグループ** を作成できること。

## 必要なツールと環境

演習を始める前に以下を準備してください。

* **[Azure CLI](https://aka.ms/install-azure-cli)** (`az`) – 認証やリソース管理に使用します。
  最新バージョンをインストールし（`az --version` で確認）、演習開始前に `az login` でサインインしてください。
* **[Azure Developer CLI](https://aka.ms/azd)** (`azd`) – インフラの構築とアプリのデプロイを簡素化します。
  `azd version` でバージョンを確認し、初回実行時にブラウザ認証が必要です（`azd auth login`）。
* **Git** – リポジトリのクローンに利用します。
  Windows の場合は [Git for Windows](https://gitforwindows.org/) や WSL に付属の Git を利用できます。
* **Python 3.10 以降** – サービスをローカル実行する場合のみ必要です。
  デプロイはコンテナで行われるため、PCに Python をインストールする必要はありません。
  ローカルで確認する場合は `requirements.txt` を参照し `pip install -r requirements.txt` で依存関係を導入します。
* **Docker** – オプションですが、コンテナイメージを自分でビルドしたりデバッグする際に便利です。
  `azd` が ACR にビルドを行いますが、ローカル Docker 環境があると問題切り分けに役立ちます。

上記ツールに加えて、**ネットワーク接続** を確認してください。
企業のプロキシ下にいる場合、`az` や `azd` が Azure に接続できるようにプロキシ設定（`HTTP_PROXY`/`HTTPS_PROXY` 環境変数や CLI の設定）が必要になる場合があります。

### Windows ユーザー向け

Windows を利用している場合は **Windows Subsystem for Linux (WSL2)** の利用を推奨します。
Ubuntu ディストリビューションをインストールし、Bash シェルで演習を進めてください。
手順は Microsoft の公式ドキュメントを参照してください。
PowerShell でもほとんどのコマンドは実行できます。

### リージョンとクォータの考慮

Cosmos DB と Container Apps はほとんどの Azure リージョンで利用できますが、レイテンシやコスト面から近いリージョンを選択するのが理想的です（例: `eastus`、`westeurope`、`japaneast` など）。
対象リージョンで Cosmos DB の **NoSQL** API と Container Apps が利用可能かを事前に確認してください。
Azure CLI では次のように確認できます。

```bash
az account list-locations --query "[].{Name:name, CosmosDB:isPreview?}" -o table
```

また、サブスクリプションに十分な **リクエストユニット (RU/s) のクォータ** があることを確認してください。
無料アカウントやトライアルではスループットに制限があります。
Azure ポータルの *Subscription* → *Usage + quotas* から確認し、必要に応じて増枠申請を行ってください。

将来的に AI 機能を追加する場合は Azure OpenAI リソースの利用権限が必要になります。
本ラボでは不要ですが、Change Feed パターンはストリーミング分析や生成 AI と組み合わせて使われることが多いことに留意してください。

### ツールチェーンの確認

演習に進む前に、お使いの PC にインストールされているツール類が動作要件を満たしているか確認しましょう。
次のコマンドを実行してバージョンを調べ、古い場合はアップデートしてください。

```bash
 # Azure CLI のバージョンを確認
 az --version

 # Azure Developer CLI のバージョンを確認
 azd version

 # Git のバージョンを確認
 git --version

 # Python インタプリタのバージョンを確認
 python --version
 # または
 python3 --version

 # Docker のバージョンを確認（任意）
 docker --version
```

本ラボでは **Azure CLI 2.77 以降**、**Azure Developer CLI 1.17 以降**、**Git 2.45.4 以降**、**Python 3.12.9 以降** を使用して検証しています。
これより古いバージョンの場合、一部機能が使えないことがありますので事前にアップデートしておきましょう。

### 作業環境の選択

本演習はローカル環境でも **Azure Cloud Shell** でも実施できます。ローカル環境ではツールのバージョンを自由に管理できる反面、セットアップが必要です。Cloud Shell はブラウザから利用でき、`az` と `azd` が事前にインストールされています。

ローカルで実行する場合は Bash や PowerShell のターミナルを用意し、前述のツールをインストールしておきます。特に Windows ユーザーは **WSL2** 上の Ubuntu 環境を利用することで Linux 向けのコマンドや Docker の利用が容易になります。PowerShell を使う場合は Bash コマンドを適宜置き換えてください。

Cloud Shell を利用するには、ブラウザで [https://shell.azure.com](https://shell.azure.com) を開き、**Bash** セッションを選択します。Cloud Shell には Azure CLI と Developer CLI がプリインストールされていますが、リポジトリをクローンするために Git をインストールする必要があるかもしれません (`sudo apt-get install git`)。Cloud Shell のストレージは Azure Files が利用されているため、大きなリポジトリを扱う場合はクローンに時間がかかることがあります。

### 環境変数とシークレットの管理

このラボでは、設定値を環境変数としてアプリに渡します。`azd up` を実行すると **環境 (environment)** が作成され、`.azure` ディレクトリに `.env` ファイルが生成されます。このファイルには Cosmos DB の接続情報やエンドポイントなどの機密情報が含まれるため、ソース管理には登録しないようにしてください。

環境変数の一覧や値は `azd env list`、`azd env get <key>` で確認でき、`azd env set <key> <value>` で変更できます。また、開発・テスト・本番など複数の環境を作成する場合は `azd env new` を使います。環境ごとにリソースグループや Cosmos DB アカウントが分離されるため、互いに影響を与えずに検証できます。

## Azure Cosmos DB アカウントの種類を理解する

このラボでは単一リージョンかつ手動スループットの Cosmos DB アカウントを使用しますが、本番環境ではワークロードに合わせたアカウントタイプを選択する必要があります。以下に代表的なタイプを示します。

* **無料枠アカウント** – 1 サブスクリプションにつき 1 つまで作成でき、最大 **1000 RU/s** と **25 GB** のストレージを無償で利用できます。学習や検証に最適ですが、後から Serverless やマルチリージョンに変更することはできません。
* **固定スループット (プロビジョンド)** – RU/s を事前に予約し安定した性能を得るタイプです。CLI (`az cosmosdb sql container throughput update`) やポータルから動的にスループットを増減できます。複数コンテナで共有する場合はデータベース単位のスループットを検討します。
* **Autoscale** – 使用量に応じて RU/s を自動的に調整します。IoT デバイスのデータ収集のように負荷が変動するワークロードに適しており、ピーク時のみ高い RU/s に課金されます。最小 RU/s は最大値の約 10% になるため、`maxThroughput` を設定する際に考慮してください。
* **Serverless** – スループットを予約せず、実際に消費した RU/s 分だけ課金されます。コンテナあたり **5 GB** までの制限があり、マルチリージョンレプリケーションは使用できません。断続的なバッチ処理や低負荷のワークロードに適します。

可用性やレイテンシを考慮してリージョンを選びます。複数リージョンでレプリケートすると災害時の復旧性が高まりますが、その分スループットとストレージのコストが各リージョンで発生します。強い整合性を選択すると遅延が増えるため、ユースケースに応じた整合性レベルの決定が重要です。

## ネットワーク計画とセキュリティ

企業や教育機関のネットワークではプロキシやファイアウォールにより外部への接続が制限されていることが多くあります。以下の対策を検討し、ラボのデプロイ前に確認しておきましょう。

* **プライベートエンドポイント** – 仮想ネットワーク内に Cosmos DB のプライベート IP を割り当て、インターネットを経由せずにアクセスできます。DNS をプライベートゾーンに設定して、`*.documents.azure.com` がプライベート IP に解決されるようにします。
* **IP ファイアウォール** – パブリックアクセスを有効にする場合でも、許可する IP 範囲を限定してください。CLI からは `az cosmosdb update --ip-range-filter` で設定できます。
* **プロキシの設定** – 組織のプロキシを経由する場合、`HTTP_PROXY` と `HTTPS_PROXY` の環境変数を設定しておくと、CLI や Docker がインターネットにアクセスできます。WSL 環境では `/etc/environment` や `apt` の設定ファイルを編集する必要があります。
* **顧客管理キー (CMK)** – Key Vault の鍵を利用して暗号化のルートキーを管理することで、コンプライアンス要件を満たすことができます。ただし、鍵のローテーションやアクセス制御が必要になります。

デプロイ前に次のコマンドでネットワーク疎通を確認しておくと安心です。

```bash
curl -I https://management.azure.com
```

接続が拒否される場合は、ネットワーク管理者に外向きの HTTPS 通信を許可してもらうよう依頼してください。

## コストの考慮

クラウドリソースは使用していなくても一定の費用がかかる場合があります。予算を抑えるために以下のポイントを意識してください。

* **スループットの適切な設定** – このラボではデータベースに 4000 RU/s を割り当てていますが、作成時に `main.parameters.json` で値を調整できます。使用状況に応じて小さく設定し、必要に応じて増やしましょう。
* **診断ログの制御** – Azure Monitor にログを送信すると Log Analytics の料金が発生します。不要な場合は Container Apps の `appLogsConfiguration` で `destination: none` を設定してログ出力を停止します。
* **リソースの削除** – 演習が終わったら `azd down` コマンドでリソースグループごと削除するか、ポータルから不要なリソースを手動で削除してください。

## ローカル開発とテストのツール

クラウドに依存せずに検証を進めるために、以下のツールを活用できます。

* **Cosmos DB Emulator** – Windows や Docker コンテナとして動作し、SQL API や Change Feed を含む Cosmos DB の機能をローカルで試すことができます。Linux からアクセスする場合は接続モードを `Gateway` に設定してください。
* **トンネルサービス (ngrok など)** – 社内ネットワークから外部へ安全にポートを公開できるツールで、ローカルで動作する Flask アプリを他の人と共有するときに便利です。
* **バージョン管理のベストプラクティス** – Git のブランチ運用 (feature ブランチ、プルリクエスト) を導入し、自動テストやコードフォーマッタを CI/CD パイプラインに組み込むことで、コード品質を維持できます。

容量計画やセキュリティ、コストの観点を事前に整理しておくことで、演習をスムーズに進めることができます。

### Cosmos DB アカウントの高度な機能

このラボでは **単一リージョン** の Cosmos DB アカウントを既定設定で作成しますが、本番運用では追加機能を有効にすることで信頼性や性能を向上できます。

* **複数書き込みリージョン** – Cosmos DB は 2 つ以上のリージョンにデータを自動レプリケートし、どのリージョンでも書き込みを受け付けます。リージョン間でレイテンシを最小化できるため、世界中に分散した IoT デバイスやゲームプレーヤーからの書き込みに適しています。Bicep の `locations` 配列でリージョンを指定します。
* **オートスケール** – RU/s を固定せず、ワークロードに応じて自動的にスループットが上下するモードです。トラフィックが急増する IoT アプリでは容量計画の負担を軽減できます。Bicep では `autoscaleSettings` で設定します。
* **専用ゲートウェイとプライベート エンドポイント** – 本番システムでは、専用ゲートウェイを利用してレイテンシを安定させたり、仮想ネットワーク内にプライベート エンドポイントを配置してアクセス範囲を限定することが一般的です。詳しくは [Cosmos DB ネットワーク構成](https://learn.microsoft.com/azure/cosmos-db/nosql/how-to-configure-network) を参照してください。

### IoT 向け分散インフラの理解

IoT やテレメトリのアプリケーションは単純な CRUD 処理以上の要件があります。ラボを進める中で以下の点を意識しましょう。

* **断続的な接続** – フィールドに設置されたデバイスは通信が途切れがちです。再接続時にイベントが集中して届いても処理できるよう、キューやバッファを設計に組み込みます。Azure IoT Hub を介して Cosmos DB へ Change Feed パターンを適用することもできます。
* **時系列モデリング** – センサー値は順不同で届くことがあり、取得間隔も一定ではありません。`sensor_id` でパーティションし、タイムスタンプでコンポジットインデックスを設定することで、最新データを効率的に問い合わせられます。本ラボの summariser では過去 10 件をスライディングウィンドウで集計します。
* **エッジ分析** – 一部のケースでは、エッジ側で初期集計を行ってからクラウドへ転送することがあります。ここで学ぶ Change Feed の設計は、IoT Edge モジュールに組み込まれたローカル Cosmos DB インスタンスでも応用可能です。

このような高度なシナリオを念頭に置くことで、本ラボで習得する基本概念を実環境へ適用する際のヒントになるでしょう。
