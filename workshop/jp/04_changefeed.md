# 4. Azure Cosmos DB Change Feed の理解

**Change Feed** は、Azure Cosmos DB に保存されたデータの変更に対して、アプリケーションがリアルタイムに反応できる機能です。
データベース全体を繰り返しクエリして変更を検出するのではなく、変更内容が記録されたログのようなストリームから読み取ります。

## 仕組み

Change Feed を有効にすると、Cosmos DB は各ドキュメントの挿入や更新を内部のログに追記します。
このログは書き込み順に保持され、各操作は **一度だけ** ストリームに現れます。
コンシューマーは次の位置から読み取りを開始できます:

* **現在以降** – これ以降の新しい変更のみを取得します。
* **先頭** – すべての履歴変更を最初から再生します。
* **継続トークン** – 以前の位置から処理を再開します。

Change Feed は元のコンテナのパーティション単位で分割されます。
そのため大規模なスループットにも対応できます。
Microsoft から提供されている **Change Feed Processor** ライブラリを使用すると、複数パーティションの読み取りやチェックポイント管理を容易に実装できます。

## 利用シナリオ

Change Feed は次のような用途に最適です。

* **新しいデータに応じたアクション** – データが到着するたびに通知を送ったり API を呼び出したりします。
* **リアルタイム分析やストリーミング ETL** – 高速なデータを即座に集計または他システムに送信します。
* **マテリアライズドビューやランキングの構築** – 生データを集約テーブルに投影します。
* **イベントソーシング** – 全てのイベント履歴を保持して状態を再構築できます。

## 設計のポイント

Change Feed を利用する際には、次の設計指針を参考にしてください。

* **パーティションキーの選択** – フィードはソースコンテナのパーティションに従うため、負荷を均等に分散できるキーを選びます。このデモでは `readings` と `summaries` の両方で `/sensor_id` を使用し、センサー単位で処理を分けています。
* **スループットの確保** – 書き込みと Change Feed の消費の両方を支える十分な RU/s を割り当てます。オートスケールを利用するとバースト負荷に対応しやすくなります。
* **並列性** – 同じコンテナに複数のコンシューマーを接続できます。その場合、リースコンテナやプレフィックスを分けて進捗を独立させます。
* **冪等性** – Change Feed は **少なくとも 1 回** の配信保証を提供するため、処理ロジックは重複イベントを正しく扱えるようにします。

これらの原則を押さえておくと、堅牢なイベント駆動アーキテクチャを構築できます。

## Change Feed Processor の仕組み

実際には、Change Feed を REST API で直接ポーリングすることはほとんどありません。
Azure Cosmos DB SDK に含まれる **Change Feed Processor (CFP)** ライブラリが複雑さを抽象化してくれます。
このライブラリは進捗を記録するために別のコンテナに **リース** ドキュメントを保存します。
各コンシューマインスタンスはパーティションの一部に対してリースを取得し、新しいアイテムを読み取り、定期的にチェックポイントを更新します。
インスタンス数を増やしてスケールアウトすると、リースは自動的に再分配されます。
本ラボでは学習目的のために直接 `read_change_feed` を呼び出していますが、実運用では CFP ライブラリや Azure Functions、Event Hubs 連携を利用することを推奨します。

CFP の基本的なループは次のような疑似コードで表せます。

```python
for page in readings_container.read_change_feed(partition_key=pk, start_time=start):
    for item in page:
        process(item)
    save_checkpoint(page.continuation)
```

継続トークンを保存しておくことで、プロセッサがクラッシュした場合でも最後に処理した位置から再開できます。
Change Feed には **少なくとも 1 回** の配信保証があるため、同じイベントが複数回配信されることに備えて、処理ロジックを **冪等** に設計する必要があります。

### スケーリングと並列性

ソースコンテナの各論理パーティションは独自の Change Feed ストリームを持っています。
ワークロードが増大した場合は RU/s を増やしたりパーティション数を増やすことで、複数のコンシューマが異なるパーティションを並列に処理できます。
CFP は次のように並列処理をコーディネートします。

* 各リースドキュメントは `readings` コンテナの物理パーティション 1 つに対応します。
* プロセッサインスタンスはリースを所有するパーティションだけを処理し、重複処理を防ぎます。
* 新しいインスタンスが起動するとリースは自動的に再バランスされます。

この仕組みによって、要求に応じて Change Feed コンシューマを水平方向にスケールアウトできます。
異なる処理を独立して実行したい場合は、それぞれ別のリースコンテナを用意してください。

### 応用パターン

Change Feed は他の Azure サービスと組み合わせて利用されることが多いです。

* **Azure Functions** – Change Feed イベントをトリガとして処理を実行できます。
  入力バインドに Cosmos DB コンテナを指定するだけで、チェックポイント管理が自動化されます。
  軽量なイベント処理やオーケストレーションに適しています。
* **Event Hubs 連携** – Cosmos DB の Change Feed を Azure Event Hubs に直接ストリーミングし、Azure Stream Analytics や Apache Kafka コンシューマでリアルタイム分析を行います。
* **Synapse Link / Azure Data Explorer** – Cosmos DB のデータを分析用ワークロードに複製するために Change Feed を内部的に使用します。
  ほぼリアルタイムで Fabric や Data Explorer のテーブルが更新されます。

どのパターンを選ぶかは、求める遅延、連携先のシステム、運用の複雑さに依存します。
このラボのシンプルなサマライザーは基本を理解するためのものですが、同じコンセプトを用いてより高度なパイプラインを構築できます。

## 最適化のテクニック

Change Feed の処理を効率化し、コストを抑えるためのヒントを紹介します。

* **バッチサイズとプリフェッチ** – SDK で `max_item_count` を指定すると、1 回の要求で取得するドキュメント数を調整できます。
  大きなバッチは 1 リクエストあたりの RU を効率化しますが、処理遅延とメモリ使用量が増えます。
  ワークロードに合わせて最適な値を見つけましょう。
* **開始位置と継続トークン** – `start_time` パラメータで過去の特定時刻から再生し、終了時には継続トークンを永続化 (Blob Storage やリースコンテナ) することで、サービス再起動時に重複なく続きを処理できます。
* **重複排除と冪等性** – 少なくとも 1 回保証を前提に、ドキュメントに複合キー `(sensor_id, window_start)` を設定して `upsert` することで重複書き込みを防ぎます。
  ユニークキー制約を設定するのも有効です。
* **フルフィデリティ vs インクリメンタル** – Cosmos DB には削除や中間更新まで含めた **フルフィデリティ Change Feed** があります。
  これは監査ログやイベントソーシングで有用ですが、ストレージと RU 消費が増えます。
  通常は最終的な状態のみを含むインクリメンタルモードで十分です。
* **リースのパーティショニング** – CFP を利用する場合は、進捗情報を保存するリースコンテナを分け、スループットを低く設定しておきます。
  パーティションキーを `/id` などで均等に分散し、アプリケーションデータと混在させないようにします。

## Azure Functions でのトリガー処理

Azure Functions には Cosmos DB トリガーが用意されており、Change Feed に新しいドキュメントが追加されるたびに関数を実行できます。
関数はデータベース名やコンテナ名、接続文字列をバインド定義で指定します。

```python
import azure.functions as func
from azure.cosmos import CosmosClient

def main(documents: func.DocumentList):
    for doc in documents:
        # 各変更ドキュメントを処理
        do_work(doc)
```

関数アプリはチェックポイントと再試行を自動で処理してくれるため、インフラ管理の手間を減らしたい場合に適しています。
コールドスタートやタイムアウトの制限があるので、高スループット用途では専用プランを検討します。

## イベントソーシングとマテリアライズドビュー

Change Feed が全ての変更を保持していることを活かし、**イベントソーシング** パターンを採用できます。
各書き込みを不変のイベントとして記録し、下流のコンシューマがイベントの再生によって状態を再構築します。
これにより完全な監査証跡が得られ、特定時点の状態を再現することが容易になります。
削除や中間更新も必要な場合はフルフィデリティモードを使用します。

効率的なクエリ提供のために、**マテリアライズドビュー** やプロジェクションを維持することがあります。
このデモでは `summaries` コンテナが単純なプロジェクションです。
より複雑なシステムでは、時間単位の集計 (時・日別) やデバイス種別別の集約、移動平均などを追加し、それぞれ専用のコンテナや Azure Data Explorer、Fabric など外部システムに保存します。

## アカウント間レプリケーションと統合パターン

大規模な組織では複数のサブスクリプションやテナントにまたがって Cosmos DB アカウントを持つことがあります。
Change Feed を利用すると、これらのアカウント間でデータを伝搬できます。

* **アカウント間レプリケーション** – ソースアカウントの Change Feed を読み、ターゲットアカウントに書き込む軽量なコピー処理を実装します。
  ターゲット側では独自のパーティションキーや整合性モデルを設定でき、セキュリティ境界を越えてデータを共有できます。
* **Event Grid 連携** – Cosmos DB の Change Feed イベントを **Event Grid** に公開すると、Azure Functions や Logic Apps、サードパーティサービスへの通知を簡単に構築できます。
  Event Grid は少なくとも 1 回の配送を保証し、イベントタイプやサブジェクトによるフィルタが可能です。
* **Cosmos DB から SQL への取り込み** – **Azure Data Factory** や **Fabric Mirroring** を使って Change Feed のデータをリレーショナルウェアハウスへ取り込むことができます。
  これにより複雑な JOIN や BI クエリが可能になります。

## リースコレクションとスループットの調整

**Change Feed Processor (CFP)** ライブラリを利用する場合、各ワーカーは論理パーティションのリースを保持します。
調整方法を理解すると並列性とコストを最適化できます。

* **リースコンテナの設計** – `leases` コンテナを別に作成し、低い RU/s (例: 400 RU/s) を設定します。
  リースキーはソースのパーティションキーから導出され、サマライザーは 1 パーティションずつ処理します。
  スケールアウトすると並列処理が増えます。
* **パーティションされたリースコレクション** – 非常に高い cardinality を持つ場合は複数のリースコンテナを使ったり、リース ID にランダムなサフィックスを付けてワーカー間で均等に配分できるようにします。
* **スループットの予算** – CFP は 1 回の読み取りあたり約 2 RU を消費します。
  センサーごとに 10 件のウィンドウを維持する場合、この読み取り量を RU 予算に組み込みます。
  `maxItemCount` や `maxDegreeOfParallelism` オプションで並列数を調整できます。

## 遅延イベントと冪等性の処理

センサーによっては過去時刻のデータ（時計のずれや再送）を送信することがあります。
正確性を担保するために以下を検討します。

* **イベント順序の管理** – ドキュメントにタイムスタンプを含め、`(sensor_id, timestamp)` に複合インデックスを設定します。
  サマライズ処理ではスライディングウィンドウより古いイベントを破棄し、ソート順に状態を更新します。
* **重複排除** – `sensor_id` と `timestamp` を組み合わせた決定論的なイベント ID (例: `UUIDv5(sensor_id + timestamp)`) を生成し、ハッシュセットや専用コンテナに格納して、既に処理済みのイベントであればスキップします。
* **冪等な書き込み** – `sensor_id` とウィンドウ境界（例: 分単位やシーケンス番号）を組み合わせた一意な ID でサマリー文書を保存し、`upsert` 操作により重複書き込みを防ぎます。

## リソース管理とコスト制御

Change Feed プロセッサの RU 消費を監視し制御することは非常に重要です。

* **バックプレッシャの処理** – RU の消費が上限に近づいたら `maxItemsPerRead` を減らすか、リースコンテナの RU/s を増やします。
  CFP は利用可能な RU に応じて自動的に読み取りを一時停止・再開します。
* **スロットリング検出** – SDK の応答ヘッダーに含まれる `x-ms-request-charge` と `x-ms-substatus` を確認し、サブステータス 10003 (レート制限) が増えていないか監視します。
  リトライが多い場合は並列度を下げます。
* **マルチリージョン料金** – 複数リージョンへの書き込みを有効にした場合、RU 消費はリージョン数に応じて増加します。
  各リージョンでの消費を見積もり、容量を調整してください。

以上のチューニングとパターンを組み合わせることで、複雑なエンタープライズシナリオに適した堅牢で効率的な Change Feed パイプラインを構築できます。
